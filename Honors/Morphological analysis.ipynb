{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5ZvggEOKnnf",
        "outputId": "a39be32b-2192-44a3-a8cd-b64a4557d25d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: running\n",
            "Porter Stemming: run\n",
            "Lancaster Stemming: run\n",
            "Snowball Stemming: run\n",
            "WordNet Lemmatization: running\n",
            "\n",
            "Generated Words: ['unworking', 'reworking', 'preworking']\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "porter_stemmer = PorterStemmer()\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "snowball_stemmer = SnowballStemmer('english')\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "word = \"running\"\n",
        "print(\"Word:\", word)\n",
        "print(\"Porter Stemming:\", porter_stemmer.stem(word))\n",
        "print(\"Lancaster Stemming:\", lancaster_stemmer.stem(word))\n",
        "print(\"Snowball Stemming:\", snowball_stemmer.stem(word))\n",
        "print(\"WordNet Lemmatization:\", wordnet_lemmatizer.lemmatize(word))\n",
        "\n",
        "prefixes = ['un', 're', 'pre']\n",
        "suffix = 'ing'\n",
        "root_word = 'work'\n",
        "\n",
        "generated_words = [prefix + root_word + suffix for prefix in prefixes]\n",
        "print(\"\\nGenerated Words:\", generated_words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/sample_text.txt', 'r') as f:\n",
        "  text = f.read()\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "words = nltk.word_tokenize(text)\n",
        "\n",
        "for word in words:\n",
        "  print(\"Word:\", word)\n",
        "  print(\"Porter Stemming:\", porter_stemmer.stem(word))\n",
        "  print(\"Lancaster Stemming:\", lancaster_stemmer.stem(word))\n",
        "  print(\"Snowball Stemming:\", snowball_stemmer.stem(word))\n",
        "  print(\"WordNet Lemmatization:\", wordnet_lemmatizer.lemmatize(word))\n",
        "  print()\n",
        "\n",
        "prefixes = ['un', 're', 'pre']\n",
        "suffix = 'ing'\n",
        "\n",
        "for word in words:\n",
        "  generated_words = [prefix + word + suffix for prefix in prefixes]\n",
        "  print(\"Generated Words:\", generated_words)\n",
        "  print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl2V1dmEKz4i",
        "outputId": "1d117475-10c0-4abd-cfc9-ecfc3b3aa04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: The\n",
            "Porter Stemming: the\n",
            "Lancaster Stemming: the\n",
            "Snowball Stemming: the\n",
            "WordNet Lemmatization: The\n",
            "\n",
            "Word: quick\n",
            "Porter Stemming: quick\n",
            "Lancaster Stemming: quick\n",
            "Snowball Stemming: quick\n",
            "WordNet Lemmatization: quick\n",
            "\n",
            "Word: brown\n",
            "Porter Stemming: brown\n",
            "Lancaster Stemming: brown\n",
            "Snowball Stemming: brown\n",
            "WordNet Lemmatization: brown\n",
            "\n",
            "Word: fox\n",
            "Porter Stemming: fox\n",
            "Lancaster Stemming: fox\n",
            "Snowball Stemming: fox\n",
            "WordNet Lemmatization: fox\n",
            "\n",
            "Word: jumps\n",
            "Porter Stemming: jump\n",
            "Lancaster Stemming: jump\n",
            "Snowball Stemming: jump\n",
            "WordNet Lemmatization: jump\n",
            "\n",
            "Word: over\n",
            "Porter Stemming: over\n",
            "Lancaster Stemming: ov\n",
            "Snowball Stemming: over\n",
            "WordNet Lemmatization: over\n",
            "\n",
            "Word: the\n",
            "Porter Stemming: the\n",
            "Lancaster Stemming: the\n",
            "Snowball Stemming: the\n",
            "WordNet Lemmatization: the\n",
            "\n",
            "Word: lazy\n",
            "Porter Stemming: lazi\n",
            "Lancaster Stemming: lazy\n",
            "Snowball Stemming: lazi\n",
            "WordNet Lemmatization: lazy\n",
            "\n",
            "Word: dogs\n",
            "Porter Stemming: dog\n",
            "Lancaster Stemming: dog\n",
            "Snowball Stemming: dog\n",
            "WordNet Lemmatization: dog\n",
            "\n",
            "Word: .\n",
            "Porter Stemming: .\n",
            "Lancaster Stemming: .\n",
            "Snowball Stemming: .\n",
            "WordNet Lemmatization: .\n",
            "\n",
            "Word: They\n",
            "Porter Stemming: they\n",
            "Lancaster Stemming: they\n",
            "Snowball Stemming: they\n",
            "WordNet Lemmatization: They\n",
            "\n",
            "Word: were\n",
            "Porter Stemming: were\n",
            "Lancaster Stemming: wer\n",
            "Snowball Stemming: were\n",
            "WordNet Lemmatization: were\n",
            "\n",
            "Word: all\n",
            "Porter Stemming: all\n",
            "Lancaster Stemming: al\n",
            "Snowball Stemming: all\n",
            "WordNet Lemmatization: all\n",
            "\n",
            "Word: amazed\n",
            "Porter Stemming: amaz\n",
            "Lancaster Stemming: amaz\n",
            "Snowball Stemming: amaz\n",
            "WordNet Lemmatization: amazed\n",
            "\n",
            "Word: by\n",
            "Porter Stemming: by\n",
            "Lancaster Stemming: by\n",
            "Snowball Stemming: by\n",
            "WordNet Lemmatization: by\n",
            "\n",
            "Word: its\n",
            "Porter Stemming: it\n",
            "Lancaster Stemming: it\n",
            "Snowball Stemming: it\n",
            "WordNet Lemmatization: it\n",
            "\n",
            "Word: agility\n",
            "Porter Stemming: agil\n",
            "Lancaster Stemming: agil\n",
            "Snowball Stemming: agil\n",
            "WordNet Lemmatization: agility\n",
            "\n",
            "Word: .\n",
            "Porter Stemming: .\n",
            "Lancaster Stemming: .\n",
            "Snowball Stemming: .\n",
            "WordNet Lemmatization: .\n",
            "\n",
            "Generated Words: ['unTheing', 'reTheing', 'preTheing']\n",
            "\n",
            "Generated Words: ['unquicking', 'requicking', 'prequicking']\n",
            "\n",
            "Generated Words: ['unbrowning', 'rebrowning', 'prebrowning']\n",
            "\n",
            "Generated Words: ['unfoxing', 'refoxing', 'prefoxing']\n",
            "\n",
            "Generated Words: ['unjumpsing', 'rejumpsing', 'prejumpsing']\n",
            "\n",
            "Generated Words: ['unovering', 'reovering', 'preovering']\n",
            "\n",
            "Generated Words: ['untheing', 'retheing', 'pretheing']\n",
            "\n",
            "Generated Words: ['unlazying', 'relazying', 'prelazying']\n",
            "\n",
            "Generated Words: ['undogsing', 'redogsing', 'predogsing']\n",
            "\n",
            "Generated Words: ['un.ing', 're.ing', 'pre.ing']\n",
            "\n",
            "Generated Words: ['unTheying', 'reTheying', 'preTheying']\n",
            "\n",
            "Generated Words: ['unwereing', 'rewereing', 'prewereing']\n",
            "\n",
            "Generated Words: ['unalling', 'realling', 'prealling']\n",
            "\n",
            "Generated Words: ['unamazeding', 'reamazeding', 'preamazeding']\n",
            "\n",
            "Generated Words: ['unbying', 'rebying', 'prebying']\n",
            "\n",
            "Generated Words: ['unitsing', 'reitsing', 'preitsing']\n",
            "\n",
            "Generated Words: ['unagilitying', 'reagilitying', 'preagilitying']\n",
            "\n",
            "Generated Words: ['un.ing', 're.ing', 'pre.ing']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "def morphological_analysis(word):\n",
        "    tokens = word_tokenize(word)\n",
        "    morph_analysis = []\n",
        "    for token in tokens:\n",
        "        synsets = wordnet.synsets(token)\n",
        "        if synsets:\n",
        "            morph_analysis.append({\n",
        "                \"word\": token,\n",
        "                \"pos\": synsets[0].pos(),\n",
        "                \"definition\": synsets[0].definition(),\n",
        "                \"lemma\": synsets[0].lemmas()[0].name(),\n",
        "                \"examples\": synsets[0].examples()\n",
        "            })\n",
        "        else:\n",
        "            morph_analysis.append({\n",
        "                \"word\": token,\n",
        "                \"pos\": None,\n",
        "                \"definition\": None,\n",
        "                \"lemma\": None,\n",
        "                \"examples\": None\n",
        "            })\n",
        "    return morph_analysis\n",
        "\n",
        "word = \"running\"\n",
        "analysis = morphological_analysis(word)\n",
        "for item in analysis:\n",
        "    print(\"Word:\", item[\"word\"])\n",
        "    print(\"Part of Speech:\", item[\"pos\"])\n",
        "    print(\"Definition:\", item[\"definition\"])\n",
        "    print(\"Lemma:\", item[\"lemma\"])\n",
        "    print(\"Examples:\", item[\"examples\"])\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS-MLwnqMhyB",
        "outputId": "722621b0-7152-43f6-94ae-994f45f90219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: running\n",
            "Part of Speech: n\n",
            "Definition: (American football) a play in which a player attempts to carry the ball through or past the opposing team\n",
            "Lemma: run\n",
            "Examples: ['the defensive line braced to stop the run', 'the coach put great emphasis on running']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "corpus = [\"apple\", \"banana\", \"orange\", \"grape\", \"kiwi\"]\n",
        "\n",
        "def generate_word(corpus):\n",
        "\n",
        "    current_word = random.choice(corpus)\n",
        "    generated_word = current_word\n",
        "\n",
        "\n",
        "    while len(generated_word) < 10:\n",
        "\n",
        "        possible_next_words = [word for word in corpus if word.startswith(current_word)]\n",
        "\n",
        "        if not possible_next_words:\n",
        "            break\n",
        "\n",
        "        next_word = random.choice(possible_next_words)\n",
        "\n",
        "        generated_word += next_word[len(current_word):]\n",
        "\n",
        "        current_word = next_word[len(current_word):]\n",
        "\n",
        "    return generated_word\n",
        "\n",
        "generated_word = generate_word(corpus)\n",
        "print(\"Generated Word:\", generated_word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe3BWYDGN72H",
        "outputId": "201e7ce6-9815-407b-8277-950e3a7c1ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Word: bananakiwi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9JiBFb0JOSn5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}