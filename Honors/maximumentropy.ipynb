{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq9sZEFc0Plq",
        "outputId": "b4ababfb-cf42-4f45-9982-02b781541821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import MaxentClassifier\n",
        "from nltk.classify import accuracy\n",
        "\n",
        "# Download NLTK resources if not already present\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Sample dataset - you should replace this with your corpus dataset\n",
        "corpus = [\n",
        "    (\"I love this movie\", \"positive\"),\n",
        "    (\"This film is great\", \"positive\"),\n",
        "    (\"That movie was terrible\", \"negative\"),\n",
        "    (\"I didn't like the acting\", \"negative\"),\n",
        "    (\"The plot was boring\", \"negative\"),\n",
        "    (\"The story was engaging\", \"positive\")\n",
        "]\n",
        "\n",
        "# Feature extraction function\n",
        "def document_features(document):\n",
        "    words = set(document)\n",
        "    features = {}\n",
        "    for word in words:\n",
        "        features['contains({})'.format(word)] = True\n",
        "    return features\n",
        "\n",
        "# Tokenization and stop word removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "processed_corpus = []\n",
        "for (text, label) in corpus:\n",
        "    words = [word.lower() for word in word_tokenize(text) if word.isalnum() and word.lower() not in stop_words]\n",
        "    processed_corpus.append((words, label))\n",
        "\n",
        "# Feature extraction\n",
        "featuresets = [(document_features(d), c) for (d,c) in processed_corpus]\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "train_set, test_set = featuresets[:int(len(featuresets)*0.8)], featuresets[int(len(featuresets)*0.8):]\n",
        "\n",
        "# Training the MaxEnt model\n",
        "classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy(classifier, test_set))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.classify import MaxentClassifier\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "\n",
        "# Prepare data\n",
        "nltk.download('movie_reviews')\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "# Define feature extractor function\n",
        "def document_features(document):\n",
        "    words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['contains({})'.format(word)] = (word in words)\n",
        "    return features\n",
        "\n",
        "# Create feature set\n",
        "all_words = FreqDist(w.lower() for w in movie_reviews.words())\n",
        "word_features = list(all_words)[:2000]\n",
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\n",
        "\n",
        "# Train the MaxEnt classifier\n",
        "classifier = MaxentClassifier.train(train_set, algorithm='GIS', max_iter=10)\n",
        "\n",
        "# Evaluate the classifier\n",
        "print(nltk.classify.accuracy(classifier, test_set))\n",
        "\n",
        "# Show most informative features\n",
        "classifier.show_most_informative_features(10)\n",
        "\n",
        "# Classify some example sentences\n",
        "sentence = \"This movie is great\"\n",
        "tokens = word_tokenize(sentence)\n",
        "features = document_features(tokens)\n",
        "print(\"Classification:\", classifier.classify(features))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sev1fW9h0UQn",
        "outputId": "ae9d45ab-6e7a-4535-b1cf-70766cb32993"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.526\n",
            "             2          -0.68779        0.526\n",
            "             3          -0.68523        0.526\n",
            "             4          -0.68269        0.526\n",
            "             5          -0.68017        0.526\n",
            "             6          -0.67766        0.526\n",
            "             7          -0.67518        0.526\n",
            "             8          -0.67271        0.530\n",
            "             9          -0.67027        0.538\n",
            "         Final          -0.66784        0.552\n",
            "0.04\n",
            "  -0.012 contains(mulan)==True and label is 'neg'\n",
            "  -0.012 contains(outstanding)==True and label is 'neg'\n",
            "  -0.011 contains(seagal)==True and label is 'pos'\n",
            "  -0.009 contains(flynt)==True and label is 'neg'\n",
            "  -0.009 contains(wonderfully)==True and label is 'neg'\n",
            "  -0.009 contains(damon)==True and label is 'neg'\n",
            "  -0.008 contains(jedi)==True and label is 'neg'\n",
            "  -0.008 contains(lame)==True and label is 'pos'\n",
            "  -0.008 contains(wasted)==True and label is 'pos'\n",
            "  -0.007 contains(awful)==True and label is 'pos'\n",
            "Classification: pos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C8Q06ikE2ctC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}